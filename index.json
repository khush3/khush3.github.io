[{"authors":["admin"],"categories":null,"content":"My interest lies in Reinforcement Learning, particularly in its application to Robotics. I have worked on Machine Learning for a while now, and have developed an ardent interest in Reinforcement Learning.\nIn my sophomore year, I started to work under Dr. Shital Chiddarwar in IvLabs and took various challenges that involved the application of Deep Learning and Reinforcement Learning.\nI\u0026rsquo;m always up to something! Here\u0026rsquo;s what\u0026rsquo;s keeping me occupied these days.\nBesides research, I enjoy listening to music, playing guitar and spending time in nature.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://khush3.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"My interest lies in Reinforcement Learning, particularly in its application to Robotics. I have worked on Machine Learning for a while now, and have developed an ardent interest in Reinforcement Learning.\nIn my sophomore year, I started to work under Dr. Shital Chiddarwar in IvLabs and took various challenges that involved the application of Deep Learning and Reinforcement Learning.\nI\u0026rsquo;m always up to something! Here\u0026rsquo;s what\u0026rsquo;s keeping me occupied these days.","tags":null,"title":"Khush Agrawal","type":"authors"},{"authors":["**Khush Agrawal**","Rohit Lal"],"categories":null,"content":"Results Check out the complete demonstration. ","date":1578594600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578594600,"objectID":"ec2c458087b334f51d51991473c6d7db","permalink":"https://khush3.github.io/publication/person_follower/","publishdate":"2020-01-10T00:00:00+05:30","relpermalink":"/publication/person_follower/","section":"publication","summary":"Helper robots are widely used in various situations, for example, at airports and railway stations. This paper presents a pipeline to multiplex the tracking and detection of a person in dynamic environments using a stereo camera in real-time. Recent developments in object detection using ConvNets have led to robust person detection. These deep convolutional neural networks generally fail to run with high frame rates on devices with less computing power. Trackers are also used to retain the identity of the target person as well as impose fewer constraints on hardware. A concept of multiplexed detection and tracking is used, which makes the pipeline faster by many folds. TurtleBot-2 is used for prototyping the robot and tuning of the motion controller. Robot Operating System (ROS) is used to set up communication between various nodes of the pipeline. The results found were comparable to current state-of-the-art person followers and can be readily used in day to day life.","tags":null,"title":"Person Following Robot using Multiplexed Detection and Tracking","type":"publication"},{"authors":null,"categories":null,"content":"•Aimed to transfer the experience of a teacher agent, receiving higher and lower dimensional observations to train student-agent, receiving only higher dimensional observations.\nAbstract Learning directly from higher dimensional data like video stream is known to be a difficult problem to tackle in Reinforcement Learning. Learning directly from higher dimensional data can also be very time consuming. Imitation Learning can be used in such cases to avoid random policy initializations. However, to use Imitation Learning, one needs to generate experience from an (expert) agent. A human (expert) agent generating these experience, needs to follow a set of ground rules to stick to the IID-data assumption needed to ensure stability in training.\nOne method to avoid the cumbersome process of setting the ground rules could be to use an (expert) agent, trained on lower dimensional observations. Training on lower dimensional data is known to be computationally efficient and less time consuming. The experience of this trained agent can hence be used to train the higher dimensional agent.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"c6e6ba2f7ae8c7fbc587cff5eaf98a56","permalink":"https://khush3.github.io/project/experience-transfer/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/project/experience-transfer/","section":"project","summary":"Framework to teach higher-dim student using experiences of a teacher.","tags":["Reinforcement Learning","Deep Learning"],"title":"Experience Transfer","type":"project"},{"authors":null,"categories":null,"content":"•Aimed at using representation learning to boost the training speed of Deep Q-Learning Algorithm.\nAbstract Learning directly from higher dimensional data like video stream is known to be a difficult problem to tackle in Reinforcement Learning. Learning directly from higher dimensional data can also be very time consuming. Representation learning can be used in such cases to leverage lower dimensional trained agents. The two-stage agent can be further be fine-tuned to adapt better.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"4d6d43aa03c8842949d504cc726312e2","permalink":"https://khush3.github.io/project/representation_rl/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/project/representation_rl/","section":"project","summary":"Framework to train agent using representation learning.","tags":["Reinforcement Learning","Deep Learning"],"title":"Representation Learning to bost Deep Q-Learning","type":"project"},{"authors":["Navid Panchi","**Khush Agrawal**","Unmesh Patil","Aniket Gujarathi","Aman Jain","Harsha Namdeo","Shital S. Chiddarwar"],"categories":null,"content":"Results Key frames as seen through robot\u0026rsquo;s eyes Predicted Actions ","date":1575138600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575138600,"objectID":"183bd3bd75c692130b3f4998efcbbfc5","permalink":"https://khush3.github.io/publication/stair_climbing/","publishdate":"2019-12-01T00:00:00+05:30","relpermalink":"/publication/stair_climbing/","section":"publication","summary":"Mobile robots are widely used in the surveillance industry, for military and industrial applications. In order to carry out surveillance tasks like urban search and rescue operations, the ability to traverse stairs is of immense significance. This paper presents a deep learning based approach for semantic segmentation of stairs, behavioral cloning for star alignment, and a novel mechanical design for an autonomous stair climbing robot. The main objective is to solve the problem of locomotion over staircases with the proposed implementation. Alignment of a robot with stairs in an image is a traditional problem, and the most recent approaches are centred around hand-crafted texture-based Gabor filters and stair detection techniques. However, we could arrive at a more scalable and robust pipeline for alignment schemes. The proposed deep learning technique eliminates the need for manual tuning of parameters of the edge detector, the Hough accumulator, and PID constants. The empirical results and architecture of the stair alignment pipeline are demonstrated in this paper.","tags":null,"title":"Deep Learning-Based Stair Segmentation and Behavioral Cloning for Autonomous Stair Climbing","type":"publication"},{"authors":null,"categories":null,"content":"Abstract To broaden my perspective on Machine Learning, I took up Reinforcement Learning courses by David Silver, Stanford CS234. To understand the nuances in the field, I implemented basic algorithms. The inspiration for the same was also drawn through a project where the idea of using Imitation Learning to overcome several limitations, struck me.\nImplementated:  DQN Vanilla Policy Gradient PPO DDPG  Results Value and Policy Iteration    Method Deterministic Frozen Lake Stochastic Frozen Lake     Value Iteration 7 8   Policy Iteration 7 3    Q-Learning Deep Q-Learning ","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"47bc177317798b160fa69ed8d5a232fa","permalink":"https://khush3.github.io/project/rl-implementation/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/project/rl-implementation/","section":"project","summary":"Implementation of basic reinforcement learning algorithms.","tags":["Reinforcement Learning","Deep Learning"],"title":"Basics of Reinforcement Learning","type":"project"},{"authors":null,"categories":null,"content":"•Aimed at developing a wirelessly controlled robot capable of moving objects.\n•Developed a 3 DoF servo controlled arm with a gripper end effector for Pick-and-Place mechanism.\n•Used 2 Arduinos for controlling arm and motion independently.\n•Used a single channel relay for optimizing power consumption by switching off the arm when not in use.\nThis project was presented for AXIS(Technical Event at NIT-Nagpur), 2017 and was awarded a prize for innovative design.\nAbstract Robots are widely used in manufacturing, assembly and packing, transport, earth and space exploration, surgery, weaponry, laboratory research, and mass production of consumer and industrial goods. A Robot equipped with a Pick-and-Place mechanism can be used for numerous applications. The gripper mechanism was created using two spur gears with one fitted to a servo and the other to a dead-axle. Four additional servos were used to create the robotic manipulator arm.\n","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"ca5aa9af3d6ff2cbd280c12835a472ad","permalink":"https://khush3.github.io/project/terra-former-robot/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/project/terra-former-robot/","section":"project","summary":"Differential Drive robot for moving objects.","tags":["Electronics","Embedded Systems","Mobile Robotics"],"title":"Terra-former Robot","type":"project"},{"authors":null,"categories":null,"content":"•Aimed at providing aid for speech-impaired people.\n•Fabricated an easy-to-use, low-cost, and lightweight device in the form of a glove.\nAbstract Description Sign languages are languages that use the visual-manual modality to convey meaning. Sign languages are expressed through manual articulations in combination with non-manual elements. Sign languages are full-fledged natural languages with their own grammar and lexicon. Unlike acoustically conveyed sound patterns, sign language uses body language and manual communication to convey the thoughts of a person fluently. It is achieved by simultaneously combining hand shapes, orientation and movement of the hands, arms or body, and facial expressions. This way of communication is, however, limited to a group of people, which introduces a communication barrier. The need for an interpreter is essential to tackle this problem. A possible approach is using computer vision and machine learning techniques. This approach can, however, be costly and needs a bulky hardware setup or particular application installation. Also, it is subject to lighting conditions and perspective problems. We devised a cost-effective and easy-to-use glove that can overcome these limitations and act as an interpreter flawlessly.\n","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554076800,"objectID":"32cbe4174f541f753e6fc5f2ca39f516","permalink":"https://khush3.github.io/project/sign-language/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/project/sign-language/","section":"project","summary":"Wearable device to aid speech-impaired people.","tags":["Electronics","Embedded Systems"],"title":"Sign Language Translator","type":"project"},{"authors":null,"categories":null,"content":"•Aimed at estimation equation of motion of a target-object video is selected to analyze its motion.\n•Aimed at retrieving data associated with the motion of target-object using elementary mathematics.\nThis project was made for TechnoSeason, 2017 and was awarded first prize.\nAbstract Simple harmonic motion can serve as a mathematical model for a variety of motions, such as the oscillation of a spring. Intending to learn computer vision and MATLAB, I worked on analyzing the motion of a target-object undergoing a damped harmonic motion. The target-object was separated from the background using color thresholding and estimated as a point object. Coordinates of this point were recorded and used to estimate the parameters associated with the mathematical model of the system like maximum displacement, mean position, the velocity at different time instants. A mathematical model was estimated by fitting a curve to the recorded data using MATLAB Curve Fitting Toolbox.\n","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525132800,"objectID":"9db3f0738d5307fc491b424326d1d6e1","permalink":"https://khush3.github.io/project/harmonic-motion-analyzer/","publishdate":"2018-05-01T00:00:00Z","relpermalink":"/project/harmonic-motion-analyzer/","section":"project","summary":"MATLAB program to analyze motion of a target object.","tags":["Computer Vision","Image Processing"],"title":"Harmonic Motion Analyzer","type":"project"},{"authors":null,"categories":null,"content":"•Designed algorithm for pose (rectangular coordinates, angle) estimation of a robot in a two dimensional plane using odometry, and developed the hardware for robot.\n•Used ROS framework to establish communication between the nodes.\n•Performed UMBmark test to calibrate robot base and wheel diameter constants .\nAbstract Robot localization is the process of determining where a mobile robot is located with respect to its environment. Localization is one of the most fundamental competencies required by an autonomous robot as the knowledge of the robot\u0026rsquo;s own location is an essential precursor to making decisions about future actions. In the summer of my freshman year, I worked on developing an algorithm to localize a differential-drive robot using odometry from scratch. I performed UMBmark test to calibrate robot base and wheel diameter constants. Besides this, I also developed the hardware for the robot.\nResults    FINAL RESULTS MEASURED DATA REAL-TIME DATA ACCURACY     ABSCISSA 25.4 cm 25.2 cm 99.3%   ORDINATE 8.3 cm 8.3 cm 100%   ANGLE 357.1 degree 356 degree 99.7%    ","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525132800,"objectID":"c440a12df96f6626729c9d9bada332a4","permalink":"https://khush3.github.io/project/pose_estim/","publishdate":"2018-05-01T00:00:00Z","relpermalink":"/project/pose_estim/","section":"project","summary":"Algorithm and Hardware for 2-D pose estimation.","tags":["Electronics","Embedded Systems","Mobile Robotics"],"title":"Localization of a differential drive robot","type":"project"}]